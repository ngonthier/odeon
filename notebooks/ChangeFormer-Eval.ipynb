{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e547dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60b66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a5e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "#plt.ioff()\n",
    "import os\n",
    "import odeon\n",
    "from odeon.data.data_module import Input\n",
    "from odeon.models.change.arch.changeformer.ChangeFormer import ChangeFormerV6\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd972235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from models.networks import *\n",
    "#from misc.metric_tool import ConfuseMatrixMeter\n",
    "#from misc.logger_tool import Logger\n",
    "#from utils import de_norm\n",
    "#import utils\n",
    "\n",
    "\n",
    "# Decide which device we want to run on\n",
    "# torch.cuda.current_device()\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def de_norm(tensor_data):\n",
    "    return tensor_data * 0.5 + 0.5\n",
    "\n",
    "\n",
    "def get_confuse_matrix(num_classes, label_gts, label_preds):\n",
    "    \"\"\"计算一组预测的混淆矩阵\"\"\"\n",
    "    def __fast_hist(label_gt, label_pred):\n",
    "        \"\"\"\n",
    "        Collect values for Confusion Matrix\n",
    "        For reference, please see: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "        :param label_gt: <np.array> ground-truth\n",
    "        :param label_pred: <np.array> prediction\n",
    "        :return: <np.ndarray> values for confusion matrix\n",
    "        \"\"\"\n",
    "        mask = (label_gt >= 0) & (label_gt < num_classes)\n",
    "        hist = np.bincount(num_classes * label_gt[mask].astype(int) + label_pred[mask],\n",
    "                           minlength=num_classes**2).reshape(num_classes, num_classes)\n",
    "        return hist\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for lt, lp in zip(label_gts, label_preds):\n",
    "        confusion_matrix += __fast_hist(lt.flatten(), lp.flatten())\n",
    "    return confusion_matrix\n",
    "\n",
    "def cm2F1(confusion_matrix):\n",
    "    hist = confusion_matrix\n",
    "    n_class = hist.shape[0]\n",
    "    tp = np.diag(hist)\n",
    "    sum_a1 = hist.sum(axis=1)\n",
    "    sum_a0 = hist.sum(axis=0)\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # 1. Accuracy & Class Accuracy\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    acc = tp.sum() / (hist.sum() + np.finfo(np.float32).eps)\n",
    "\n",
    "    # recall\n",
    "    recall = tp / (sum_a1 + np.finfo(np.float32).eps)\n",
    "    # acc_cls = np.nanmean(recall)\n",
    "\n",
    "    # precision\n",
    "    precision = tp / (sum_a0 + np.finfo(np.float32).eps)\n",
    "\n",
    "    # F1 score\n",
    "    F1 = 2 * recall * precision / (recall + precision + np.finfo(np.float32).eps)\n",
    "    mean_F1 = np.nanmean(F1)\n",
    "    return mean_F1\n",
    "\n",
    "\n",
    "###################       metrics      ###################\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg\n",
    "\n",
    "    def get_scores(self):\n",
    "        scores_dict = cm2score(self.sum)\n",
    "        return scores_dict\n",
    "\n",
    "    def clear(self):\n",
    "        self.initialized = False\n",
    "\n",
    "###################      cm metrics      ###################\n",
    "class ConfuseMatrixMeter(AverageMeter):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, n_class):\n",
    "        super(ConfuseMatrixMeter, self).__init__()\n",
    "        self.n_class = n_class\n",
    "\n",
    "    def update_cm(self, pr, gt, weight=1):\n",
    "        \"\"\"获得当前混淆矩阵，并计算当前F1得分，并更新混淆矩阵\"\"\"\n",
    "        val = get_confuse_matrix(num_classes=self.n_class, label_gts=gt, label_preds=pr)\n",
    "        self.update(val, weight)\n",
    "        current_score = cm2F1(val)\n",
    "        return current_score\n",
    "\n",
    "    def get_scores(self):\n",
    "        scores_dict = cm2score(self.sum)\n",
    "        return scores_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "216fbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CDEvaluator():\n",
    "\n",
    "    def __init__(self, dataloader, checkpoint_dir, n_class = 2, embed_dim = 256, gpu_ids = []):\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "\n",
    "        self.n_class = n_class\n",
    "        # define G\n",
    "        #self.net_G = define_G(args=args, gpu_ids=args.gpu_ids)\n",
    "        self.net_G = ChangeFormerV6(embed_dim=embed_dim)\n",
    "        self.device = torch.device(\"cuda:%s\" % gpu_ids[0] if torch.cuda.is_available() and len(gpu_ids)>0\n",
    "                                   else \"cpu\")\n",
    "        print(self.device)\n",
    "\n",
    "        # define some other vars to record the training states\n",
    "        self.running_metric = ConfuseMatrixMeter(n_class=self.n_class)\n",
    "\n",
    "        # define logger file\n",
    "        #logger_path = os.path.join(args.checkpoint_dir, 'log_test.txt')\n",
    "        #self.logger = Logger(logger_path)\n",
    "        #self.logger.write_dict_str(args.__dict__)\n",
    "\n",
    "\n",
    "        #  training log\n",
    "        self.epoch_acc = 0\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_epoch_id = 0\n",
    "\n",
    "        self.steps_per_epoch = len(dataloader)\n",
    "\n",
    "        self.G_pred = None\n",
    "        self.pred_vis = None\n",
    "        self.batch = None\n",
    "        self.is_training = False\n",
    "        self.batch_id = 0\n",
    "        self.epoch_id = 0\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "#         self.vis_dir = args.vis_dir\n",
    "\n",
    "        # check and create model dir\n",
    "        if os.path.exists(self.checkpoint_dir) is False:\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "#         if os.path.exists(self.vis_dir) is False:\n",
    "#             os.mkdir(self.vis_dir)\n",
    "\n",
    "\n",
    "    def _load_checkpoint(self, checkpoint_name='best_ckpt.pt'):\n",
    "\n",
    "        if os.path.exists(os.path.join(self.checkpoint_dir, checkpoint_name)):\n",
    "            print('loading last checkpoint...\\n')\n",
    "            # load the entire checkpoint\n",
    "            checkpoint = torch.load(os.path.join(self.checkpoint_dir, checkpoint_name), map_location=self.device)\n",
    "\n",
    "            self.net_G.load_state_dict(checkpoint['model_G_state_dict'])\n",
    "\n",
    "            self.net_G.to(self.device)\n",
    "\n",
    "            # update some other states\n",
    "            self.best_val_acc = checkpoint['best_val_acc']\n",
    "            self.best_epoch_id = checkpoint['best_epoch_id']\n",
    "\n",
    "            print('Eval Historical_best_acc = %.4f (at epoch %d)\\n' %\n",
    "                  (self.best_val_acc, self.best_epoch_id))\n",
    "            print('\\n')\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError('no such checkpoint %s' % checkpoint_name)\n",
    "\n",
    "\n",
    "    def _visualize_pred(self):\n",
    "        pred = torch.argmax(self.G_pred, dim=1, keepdim=True)\n",
    "        pred_vis = pred * 255\n",
    "        return pred_vis\n",
    "\n",
    "\n",
    "    def _update_metric(self):\n",
    "        \"\"\"\n",
    "        update metric\n",
    "        \"\"\"\n",
    "        target = self.batch['mask'].to(self.device).detach()\n",
    "        G_pred = self.G_pred.detach()\n",
    "        G_pred = torch.argmax(G_pred, dim=1)\n",
    "\n",
    "        current_score = self.running_metric.update_cm(pr=G_pred.cpu().numpy(), gt=target.cpu().numpy())\n",
    "        return current_score\n",
    "\n",
    "    def _collect_running_batch_states(self):\n",
    "\n",
    "        running_acc = self._update_metric()\n",
    "\n",
    "#         m = len(self.dataloader)\n",
    "\n",
    "#         if np.mod(self.batch_id, 100) == 1:\n",
    "#             message = 'Is_training: %s. [%d,%d],  running_mf1: %.5f\\n' %\\\n",
    "#                       (self.is_training, self.batch_id, m, running_acc)\n",
    "#             self.logger.write(message)\n",
    "\n",
    "#         if np.mod(self.batch_id, 100) == 1:\n",
    "#             vis_input = utils.make_numpy_grid(de_norm(self.batch['A']))\n",
    "#             vis_input2 = utils.make_numpy_grid(de_norm(self.batch['B']))\n",
    "\n",
    "#             vis_pred = utils.make_numpy_grid(self._visualize_pred())\n",
    "\n",
    "#             vis_gt = utils.make_numpy_grid(self.batch['L'])\n",
    "#             vis = np.concatenate([vis_input, vis_input2, vis_pred, vis_gt], axis=0)\n",
    "#             vis = np.clip(vis, a_min=0.0, a_max=1.0)\n",
    "#             file_name = os.path.join(\n",
    "#                 self.vis_dir, 'eval_' + str(self.batch_id)+'.jpg')\n",
    "#             plt.imsave(file_name, vis)\n",
    "\n",
    "\n",
    "    def _collect_epoch_states(self):\n",
    "\n",
    "        scores_dict = self.running_metric.get_scores()\n",
    "\n",
    "        np.save(os.path.join(self.checkpoint_dir, 'scores_dict.npy'), scores_dict)\n",
    "\n",
    "        self.epoch_acc = scores_dict['mf1']\n",
    "\n",
    "        with open(os.path.join(self.checkpoint_dir, '%s.txt' % (self.epoch_acc)),\n",
    "                  mode='a') as file:\n",
    "            pass\n",
    "\n",
    "        message = ''\n",
    "        for k, v in scores_dict.items():\n",
    "            message += '%s: %.5f ' % (k, v)\n",
    "        self.logger.write('%s\\n' % message)  # save the message\n",
    "\n",
    "        self.logger.write('\\n')\n",
    "\n",
    "    def _clear_cache(self):\n",
    "        self.running_metric.clear()\n",
    "\n",
    "    def _forward_pass(self, batch):\n",
    "        self.batch = batch\n",
    "        img_in1 = batch['T0'].to(self.device)\n",
    "        img_in2 = batch['T1'].to(self.device)\n",
    "        x = torch.stack(tensors=(img_in1, img_in2), dim=1)\n",
    "        self.G_pred = self.net_G(x)\n",
    "\n",
    "    def eval_models(self,checkpoint_name='best_ckpt.pt'):\n",
    "\n",
    "        self._load_checkpoint(checkpoint_name)\n",
    "\n",
    "        ################## Eval ##################\n",
    "        ##########################################\n",
    "        print('Begin evaluation...\\n')\n",
    "        self._clear_cache()\n",
    "        self.is_training = False\n",
    "        self.net_G.eval()\n",
    "\n",
    "        # Iterate over data.\n",
    "        for self.batch_id, batch in enumerate(self.dataloader, 0):\n",
    "            with torch.no_grad():\n",
    "                self._forward_pass(batch)\n",
    "            self._collect_running_batch_states()\n",
    "        self._collect_epoch_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13684094",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_workers = 8\n",
    "\n",
    "cur_levir_path = Path(\"/mnt/store_dai/datasrc/dchan/levir-cd-repatched-256x256\")\n",
    "\n",
    "train_params = {\n",
    "    'input_fields': {\n",
    "        \"T0\": {\"name\": \"A\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"T1\": {\"name\": \"B\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"mask\": {\"name\": \"label\", \"type\": \"mask\", \"encoding\": \"integer\"}\n",
    "    },\n",
    "    'dataloader_options' : {\"batch_size\": batch_size, \"num_workers\": num_workers},\n",
    "    'input_file': cur_levir_path / \"train.csv\",\n",
    "    'input_files_has_header': 'infer',\n",
    "    'root_dir': cur_levir_path,\n",
    "    'nb_samples': 0,\n",
    "    'sample_seed': 0\n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'input_fields': {\n",
    "        \"T0\": {\"name\": \"A\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"T1\": {\"name\": \"B\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"mask\": {\"name\": \"label\", \"type\": \"mask\", \"encoding\": \"integer\"}\n",
    "    },\n",
    "    'dataloader_options' : {\"batch_size\": batch_size, \"num_workers\": num_workers},\n",
    "    'input_file': cur_levir_path / \"val.csv\",\n",
    "    'input_files_has_header': 'infer',\n",
    "    'root_dir': cur_levir_path,\n",
    "    'nb_samples': 0,\n",
    "    'sample_seed': 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    'input_fields': {\n",
    "        \"T0\": {\"name\": \"A\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"T1\": {\"name\": \"B\", \"type\": \"raster\", \"dtype\": \"uint8\", \"band_indices\": [1, 2, 3]},\n",
    "        \"mask\": {\"name\": \"label\", \"type\": \"mask\", \"encoding\": \"integer\"}\n",
    "    },\n",
    "    'dataloader_options' : {\"batch_size\": batch_size, \"num_workers\": num_workers},\n",
    "    'input_file': cur_levir_path / \"test.csv\",\n",
    "    'root_dir': cur_levir_path,\n",
    "    'input_files_has_header': 'infer',\n",
    "    'nb_samples': 0,\n",
    "    'sample_seed': 0\n",
    "}\n",
    "\n",
    "\n",
    "input = Input(\n",
    "    fit_params=train_params,\n",
    "    validate_params=val_params,\n",
    "    test_params=test_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05956aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.prepare_data()\n",
    "input.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24b34ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = CDEvaluator(\n",
    "    dataloader=input.validate.dataloader,\n",
    "    checkpoint_dir=\"/mnt/store_dai/equipiers/pvoitot/dchan/checkpoints/ChangeFormerV6_LEVIR_ckpt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07b1931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading last checkpoint...\n",
      "\n",
      "Eval Historical_best_acc = 0.9495 (at epoch 176)\n",
      "\n",
      "\n",
      "\n",
      "Begin evaluation...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/PVoitot/mambaforge/envs/odeon/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cm2score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 157\u001b[0m, in \u001b[0;36mCDEvaluator.eval_models\u001b[0;34m(self, checkpoint_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pass(batch)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_running_batch_states()\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_epoch_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 114\u001b[0m, in \u001b[0;36mCDEvaluator._collect_epoch_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_epoch_states\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 114\u001b[0m     scores_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores_dict.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), scores_dict)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_acc \u001b[38;5;241m=\u001b[39m scores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmf1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[49], line 117\u001b[0m, in \u001b[0;36mConfuseMatrixMeter.get_scores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     scores_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcm2score\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores_dict\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm2score' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
